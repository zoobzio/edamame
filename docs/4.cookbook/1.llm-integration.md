---
title: LLM Integration
description: Using edamame specs with AI assistants
author: zoobzio
published: 2025-12-17
updated: 2025-12-17
tags:
  - LLM
  - AI
  - Integration
  - Specs
---

# LLM Integration

Edamame's introspection makes it ideal for AI-assisted database operations.

## The Pattern

1. Export factory specs as JSON
2. Provide specs to an LLM as context
3. LLM generates capability names and params
4. Execute capabilities with LLM-provided inputs

```
User Query → LLM (with specs) → Capability + Params → Edamame → Results
```

## Exporting Specs

```go
factory, _ := edamame.New[User](db, "users")

// Add domain-specific capabilities
factory.AddQuery(edamame.QueryCapability{
    Name:        "by-role",
    Description: "Find users by role",
    Spec: edamame.QuerySpec{
        Where: []edamame.ConditionSpec{
            {Field: "role", Operator: "=", Param: "role"},
        },
    },
})

factory.AddQuery(edamame.QueryCapability{
    Name:        "active-adults",
    Description: "Find active users over 18",
    Spec: edamame.QuerySpec{
        Where: []edamame.ConditionSpec{
            {Field: "active", Operator: "=", Param: "active"},
            {Field: "age", Operator: ">=", Param: "min_age"},
        },
    },
})

// Export as JSON
json, _ := factory.SpecJSON()
```

Example output:

```json
{
  "table": "users",
  "queries": [
    {
      "name": "query",
      "description": "Query all users records",
      "params": []
    },
    {
      "name": "by-role",
      "description": "Find users by role",
      "params": [
        {"name": "role", "type": "text", "required": true}
      ]
    },
    {
      "name": "active-adults",
      "description": "Find active users over 18",
      "params": [
        {"name": "active", "type": "boolean", "required": true},
        {"name": "min_age", "type": "integer", "required": true}
      ]
    }
  ],
  "selects": [
    {
      "name": "select",
      "description": "Select a single users by primary key",
      "params": [
        {"name": "id", "type": "integer", "required": true}
      ]
    }
  ],
  "aggregates": [
    {
      "name": "count",
      "description": "Count all users records",
      "params": []
    }
  ]
}
```

## System Prompt Design

Provide specs in your LLM system prompt:

```
You are a database assistant. You have access to the following capabilities:

{specs_json}

When the user asks a question about data:
1. Identify the appropriate capability
2. Extract required parameters from the user's request
3. Respond with JSON: {"capability": "name", "type": "query|select|...", "params": {...}}

Examples:
- "How many users are there?" → {"capability": "count", "type": "aggregate", "params": {}}
- "Find admins" → {"capability": "by-role", "type": "query", "params": {"role": "admin"}}
- "Get user 123" → {"capability": "select", "type": "select", "params": {"id": 123}}
```

## Executing LLM Responses

Parse and execute LLM responses:

```go
type LLMResponse struct {
    Capability string         `json:"capability"`
    Type       string         `json:"type"`
    Params     map[string]any `json:"params"`
}

func ExecuteLLMResponse(ctx context.Context, factory *edamame.Factory[User], resp LLMResponse) (any, error) {
    switch resp.Type {
    case "query":
        return factory.ExecQuery(ctx, resp.Capability, resp.Params)
    case "select":
        return factory.ExecSelect(ctx, resp.Capability, resp.Params)
    case "aggregate":
        return factory.ExecAggregate(ctx, resp.Capability, resp.Params)
    case "update":
        return factory.ExecUpdate(ctx, resp.Capability, resp.Params)
    case "delete":
        return factory.ExecDelete(ctx, resp.Capability, resp.Params)
    default:
        return nil, fmt.Errorf("unknown capability type: %s", resp.Type)
    }
}
```

## Multi-Table Support

Aggregate specs from multiple factories:

```go
type DatabaseSpec struct {
    Tables map[string]edamame.FactorySpec `json:"tables"`
}

func BuildDatabaseSpec(factories map[string]any) DatabaseSpec {
    spec := DatabaseSpec{Tables: make(map[string]edamame.FactorySpec)}

    for name, f := range factories {
        // Type assert to get Spec()
        switch factory := f.(type) {
        case *edamame.Factory[User]:
            spec.Tables[name] = factory.Spec()
        case *edamame.Factory[Order]:
            spec.Tables[name] = factory.Spec()
        // ... more types
        }
    }

    return spec
}
```

## Validation

Validate LLM responses before execution:

```go
func ValidateLLMResponse(factory *edamame.Factory[User], resp LLMResponse) error {
    switch resp.Type {
    case "query":
        if !factory.HasQuery(resp.Capability) {
            return fmt.Errorf("unknown query capability: %s", resp.Capability)
        }
        cap, _ := factory.GetQuery(resp.Capability)
        return validateParams(cap.Params, resp.Params)
    case "select":
        if !factory.HasSelect(resp.Capability) {
            return fmt.Errorf("unknown select capability: %s", resp.Capability)
        }
        cap, _ := factory.GetSelect(resp.Capability)
        return validateParams(cap.Params, resp.Params)
    // ... other types
    }
    return nil
}

func validateParams(specs []edamame.ParamSpec, provided map[string]any) error {
    for _, spec := range specs {
        if spec.Required {
            if _, ok := provided[spec.Name]; !ok {
                return fmt.Errorf("missing required param: %s", spec.Name)
            }
        }
    }
    return nil
}
```

## Rate Limiting

Protect against LLM-driven query floods:

```go
type RateLimitedExecutor struct {
    factory *edamame.Factory[User]
    limiter *rate.Limiter
}

func NewRateLimitedExecutor(factory *edamame.Factory[User], rps float64) *RateLimitedExecutor {
    return &RateLimitedExecutor{
        factory: factory,
        limiter: rate.NewLimiter(rate.Limit(rps), 10),
    }
}

func (e *RateLimitedExecutor) Execute(ctx context.Context, resp LLMResponse) (any, error) {
    if err := e.limiter.Wait(ctx); err != nil {
        return nil, err
    }
    return ExecuteLLMResponse(ctx, e.factory, resp)
}
```

## Audit Logging

Log LLM-driven operations:

```go
func ExecuteWithAudit(ctx context.Context, factory *edamame.Factory[User], resp LLMResponse, userID string) (any, error) {
    start := time.Now()

    result, err := ExecuteLLMResponse(ctx, factory, resp)

    // Log the operation
    log.Printf("LLM execution: user=%s capability=%s type=%s params=%v duration=%v error=%v",
        userID,
        resp.Capability,
        resp.Type,
        resp.Params,
        time.Since(start),
        err,
    )

    return result, err
}
```

## Example: Chat Interface

Complete example with a simple chat interface:

```go
func HandleChat(ctx context.Context, factory *edamame.Factory[User], llm LLMClient, userMessage string) string {
    // 1. Get specs
    specs, _ := factory.SpecJSON()

    // 2. Build prompt
    prompt := fmt.Sprintf(`You are a database assistant. Available capabilities:
%s

User: %s

Respond with JSON: {"capability": "...", "type": "...", "params": {...}}
Or respond with {"error": "..."} if the request cannot be fulfilled.`, specs, userMessage)

    // 3. Get LLM response
    llmResp, err := llm.Complete(ctx, prompt)
    if err != nil {
        return "I couldn't process that request."
    }

    // 4. Parse response
    var resp LLMResponse
    if err := json.Unmarshal([]byte(llmResp), &resp); err != nil {
        return "I couldn't understand how to query the database."
    }

    // 5. Validate
    if err := ValidateLLMResponse(factory, resp); err != nil {
        return fmt.Sprintf("Invalid request: %v", err)
    }

    // 6. Execute
    result, err := ExecuteLLMResponse(ctx, factory, resp)
    if err != nil {
        return fmt.Sprintf("Query failed: %v", err)
    }

    // 7. Format response
    return formatResult(result)
}
```

## Security Considerations

- **Validate all LLM outputs** before execution
- **Use parameterized queries** (edamame handles this)
- **Limit exposed capabilities** to what's safe
- **Rate limit** LLM-driven operations
- **Audit log** all executions
- **Never expose** raw SQL generation to LLMs
